{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Простейшая нейронная сеть\n",
    "\n",
    "Пример инспирирован: https://github.com/stmorgan/pythonNNexample\n",
    "\n",
    "Видео: https://youtu.be/h3l4qz76JhQ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция активации и её производная\n",
    "\n",
    "Производная для градиентного спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array as na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции numpy и её операции покомпонентно работают с векторами\n",
    "\n",
    "def σ(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dσ_dx(x):\n",
    "    return x * (1- x)\n",
    "\n",
    "learning_throttle = 1.0\n",
    "iterations = 60000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучающие данные. Во входном слое также есть т.н. *нейрон смещения*, который всегда 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Входные данные\n",
    "X = [\n",
    "    na([[0],[0],[1]]),\n",
    "    na([[0],[1],[1]]),\n",
    "    na([[1],[0],[1]]),\n",
    "    na([[1],[1],[1]])\n",
    "]\n",
    "\n",
    "# Выходные данные — XOR и =>\n",
    "Z = [\n",
    "    na([[0], [1]]),\n",
    "    na([[1], [1]]),\n",
    "    na([[1], [0]]),\n",
    "    na([[0], [1]])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seed for the random generator is set so that it will return the same random numbers each time re-running the script, which is sometimes useful for debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we intialize the weights to random values. syn0 are the weights between the input layer and the hidden layer.  It is a 3x4 matrix because there are two input weights plus a bias term (=3) and four nodes in the hidden layer (=4). syn1 are the weights between the hidden layer and the output layer. It is a 4x1 matrix because there are 4 nodes in the hidden layer and one output. Note that there is no bias term feeding the output layer in this example. The weights are initially generated randomly because optimization tends not to work well when all the weights start at the same value. Note that neither of the neural networks shown in the video describe the example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "#synapses\n",
    "s_0 = 2*np.random.random((4,3)) - 1  # 3x4 matrix of weights ((2 inputs + 1 bias) x 4 nodes in the hidden layer)\n",
    "s_1 = 2*np.random.random((2,4)) - 1  # 4x2 matrix of weights. (4 nodes x 2 outputs) - no bias term in the hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main training loop. The output shows the evolution of the error between the model and desired. The error steadily decreases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.6044998041745449\n",
      "Error: 0.009578664905779232\n",
      "Error: 0.006452649250187106\n",
      "Error: 0.005148693269119228\n",
      "Error: 0.004394195392512397\n",
      "Error: 0.003889130768711994\n",
      "Output after training\n",
      "[[0.00352153]\n",
      " [0.99895198]]\n"
     ]
    }
   ],
   "source": [
    "for j in range(iterations):\n",
    "    for x, z in zip(X, Z):\n",
    "    \n",
    "        # Применим нейронную сеть\n",
    "        l_0 = x\n",
    "        l_1 = σ(s_0 @ l_0)\n",
    "        l_2 = σ(s_1 @ l_1)\n",
    "        \n",
    "        # Обратное распространение ошибки \n",
    "        ε_l_2 = z - l_2\n",
    "        Δ_l_2 = ε_l_2 * dσ_dx(l_2) * learning_throttle\n",
    "        \n",
    "        ε_l_1 = s_1.T @ Δ_l_2\n",
    "        Δ_l_1 = ε_l_1 * dσ_dx(l_1) * learning_throttle\n",
    "    \n",
    "        # Коррекция весов\n",
    "        s_1 += Δ_l_2 @ l_1.T\n",
    "        s_0 += Δ_l_1 @ l_0.T\n",
    "    \n",
    "    if j % 10000 == 0:   # Only print the error every 10000 steps, to save time and limit the amount of output. \n",
    "        print(\"Error: \" + str(np.max(np.abs(ε_l_2))))\n",
    "\n",
    "    \n",
    "print(\"Output after training\")\n",
    "print(l_2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the final output closely approximates the true output [0, 1, 1, 0]. If you increase the number of interations in the training loop (currently 60000), the final output will be even closer.\n",
    "\n",
    "А теперь давайте протестируем сеть..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00273101 0.99709937]\n",
      "[0.99662297 0.99887719]\n",
      "[0.99664211 0.00437073]\n",
      "[0.00352123 0.99895205]\n"
     ]
    }
   ],
   "source": [
    "def predict(arg):\n",
    "    arg += [1]\n",
    "    l_1 = σ(s_0 @ arg)\n",
    "    l_2 = σ(s_1 @ l_1)\n",
    "    return l_2\n",
    "\n",
    "print(predict([0,0]))\n",
    "print(predict([0,1]))\n",
    "print(predict([1,0]))\n",
    "print(predict([1,1]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
